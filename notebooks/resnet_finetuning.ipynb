{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Fine-Tuning\n",
    "\n",
    "LOSO CV to obtain a ResNet50 fine-tuned feature extractor to generate the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, jaccard_score, f1_score\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#Import ResNet50\n",
    "from torchvision import models, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numbers\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['figure.dpi'] = 125 #high resolution\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_frames(root_data_path, csv_file):\n",
    "    \"\"\"\n",
    "    Compute the number of frames based on the .pkl files in the specified directory.\n",
    "    Args:\n",
    "        root_dir (str): Path to the directory containing .pkl files.\n",
    "    Returns:\n",
    "        int: Number of frames.\n",
    "    \"\"\"\n",
    "    n_frames = 0\n",
    "    for file in csv_file['files']:\n",
    "        pkl_path = os.path.join(root_data_path, file)\n",
    "        if os.path.exists(pkl_path):\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                n_frames += data['image_feats'].shape[0]\n",
    "        else:\n",
    "            print(f\"Warning: {pkl_path} does not exist.\")\n",
    "\n",
    "    return n_frames\n",
    "\n",
    "def load_data(root_data_path, fold_data_path, csv_filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Load data from the specified directory and return tensors for image features, \n",
    "    kinematics features, gesture labels, error labels, task labels, trial labels, and subject labels.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The directory containing the data files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing tensors/dfs for image features, kinematics features, \n",
    "           gesture labels, error labels, task labels, trial labels, and subject labels.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_file = pd.read_csv(os.path.join(fold_data_path, csv_filename), header=None, names=['files'])\n",
    "    n_frames = compute_n_frames(root_data_path, csv_file)\n",
    "\n",
    "    image_data = torch.empty((n_frames, 3, 224, 224))\n",
    "    e_labels_data = torch.empty((n_frames, 5))\n",
    "\n",
    "    frame_index = 0\n",
    "    for pkl_file in csv_file['files']:\n",
    "\n",
    "        \n",
    "        if pkl_file.endswith('.pkl'):\n",
    "            pkl_path = os.path.join(root_data_path, pkl_file)\n",
    "            with open(pkl_path, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            n_frames_in_trial = data['image_feats'].shape[0]\n",
    "\n",
    "            #i. Image features\n",
    "            image_data[frame_index : frame_index + n_frames_in_trial] = data['image_feats']\n",
    "            print(\"Max of image_data: \", image_data.max(), \" Min of image_data: \", image_data.min())\n",
    "            e_labels_data[frame_index : frame_index + n_frames_in_trial] = data['e_labels']\n",
    "            frame_index += n_frames_in_trial\n",
    "\n",
    "    return image_data, e_labels_data\n",
    "\n",
    "\n",
    "def train_single_epoch(model, train_dataloader, device, criterion, optimizer):\n",
    "    torch.mps.manual_seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, labels) in tqdm.tqdm(enumerate(train_dataloader),\n",
    "                                            total = len(train_dataloader)):\n",
    "        \n",
    "        if i == 0:\n",
    "            train_loss, correct_train, total_train = 0, 0, 0\n",
    "\n",
    "        images, labels = images.type(torch.float32).to(device), labels.type(torch.float32).to(device)\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images).view(-1, 1)\n",
    "        labels = labels.view(-1, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Metrics\n",
    "        train_loss += loss.item()\n",
    "        preds = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        #Eliminate images and labels from device\n",
    "        images = images.cpu()\n",
    "        labels = labels.cpu()\n",
    "\n",
    "\n",
    "    return train_loss, correct_train, total_train \n",
    "\n",
    "\n",
    "def validate_single_epoch(model, dataloader, device, criterion, compute_accuracy=False, store_preds=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Validate the model for a single epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to validate.\n",
    "        dataloader (DataLoader): DataLoader for the validation set.\n",
    "        device (torch.device): Device to run the model on.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        compute_accuracy (bool): Whether to compute accuracy.\n",
    "        store_preds (bool): Whether to store predictions.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        if compute_accuracy is True:\n",
    "            loss, accuracy\n",
    "        \n",
    "        if store_preds is True:\n",
    "            loss, accuracy, preds, labels\n",
    "        \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    torch.mps.manual_seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (images, labels) in tqdm.tqdm(enumerate(dataloader),\n",
    "                                                total = len(dataloader)):\n",
    "            if i == 0 and compute_accuracy:\n",
    "                loss_total, correct, total = 0, 0, 0 \n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            #Forward pass\n",
    "            outputs = model(images).view(-1, 1)\n",
    "            \n",
    "            labels = labels.view(-1, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            #Metrics\n",
    "            loss_total += loss.item()\n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "            if compute_accuracy:\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "def compute_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Compute features using the model for the given dataloader.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to use for feature extraction.\n",
    "        dataloader (DataLoader): DataLoader for the dataset.\n",
    "        device (torch.device): Device to run the model on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Extracted features.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    features = torch.empty((0, 2048))  # Assuming ResNet50 output features are of size 2048\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm.tqdm(dataloader, total=len(dataloader)):\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            features = torch.cat((features, output.cpu()), dim=0)\n",
    "\n",
    "    return torch.cat(features, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, val_losses, first_epoch=0, test=False, out=None):\n",
    "    #Function to plot the train and validation losses\n",
    "    #Inputs: train_losses, val_losses\n",
    "\n",
    "    #Compute best epoch\n",
    "    #best_epoch = early_stopping(val_losses)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    out = \"Trial \" + out[0] + \" Out\"\n",
    "    plt.title(f\"Evolution of Loss for Setting {out}\")\n",
    "    epochs = range(first_epoch, len(train_losses))\n",
    "    plt.plot(epochs, train_losses[first_epoch:], label=\"Train Loss\")\n",
    "    if test:\n",
    "        plt.plot(epochs, val_losses[first_epoch:], label=\"Test Loss\", linestyle=\"--\")\n",
    "    else:\n",
    "        plt.plot(epochs, val_losses[first_epoch:], label=\"Val Loss\", linestyle=\"--\")\n",
    "    #plt.axvline(x=best_epoch, color=\"red\", linestyle=\"--\")\n",
    "    #plt.text(best_epoch, 0.3, f\"Best epoch: {best_epoch}\")\n",
    "    plt.xlabel(\"Epoch\", fontsize = 15)\n",
    "    plt.ylabel(\"Loss\", fontsize = 15)\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accs(train_acc, val_acc, first_epoch=0, test=False, out=None):\n",
    "    #Function to plot the train and validation losses\n",
    "    #Inputs: train_losses, val_losses\n",
    "\n",
    "    #Compute best epoch\n",
    "    #best_epoch = early_stopping(val_losses)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    out = \"Trial \" + out[0] + \" Out\"\n",
    "    plt.title(f\"Evolution of Accuracy for Setting {out}\")\n",
    "    epochs = range(first_epoch, len(train_acc))\n",
    "    plt.plot(epochs, train_acc[first_epoch:], label=\"Train Accuracy\")\n",
    "    if test:\n",
    "        plt.plot(epochs, val_acc[first_epoch:], label=\"Test Accuracy\", linestyle=\"--\")\n",
    "    else:\n",
    "        plt.plot(epochs, val_acc[first_epoch:], label=\"Val Accuracy\", linestyle=\"--\")\n",
    "    #plt.axvline(x=best_epoch, color=\"red\", linestyle=\"--\")\n",
    "    #plt.text(best_epoch, 0.3, f\"Best epoch: {best_epoch}\")\n",
    "    plt.xlabel(\"Epoch\", fontsize = 15)\n",
    "    plt.ylabel(\"Accuracy\", fontsize = 15)\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_sklearn_reports(y_true, y_pred, train_or_val, fig = None, ax = None):   \n",
    "    \n",
    "    confusion_matrix_train = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_train, display_labels=['0 (No error)', '1 (Error)'])\n",
    "    disp.plot(ax=ax, cmap = 'Blues')\n",
    "    disp.ax_.set_title(f'Confusion Matrix {train_or_val} Set')\n",
    "\n",
    "    # Classification report train set\n",
    "    print(f\"Classification report for {train_or_val} set:\", \"\\n\", classification_report(y_true, y_pred, target_names=['0 (No error)', '1 (Error)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset class (to be moved to dataset.py)\n",
    "\n",
    "class CustomVideoDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Custom dataset to load data and arrange it in windows.\n",
    "    Input:\n",
    "        image_data: Tensor of image features. Shape: n_samples x 2048\n",
    "        kinematics_data: Tensor of kinematics features. Shape: n_samples x 26\n",
    "        g_labels_data: Tensor of gesture labels. Shape: n_samples x 1   \n",
    "        e_labels_data: Tensor of error labels. Shape: n_samples x 5\n",
    "        task_data: Tensor of task labels. Shape: n_samples x 1\n",
    "        trial_data: Tensor of trial labels. Shape: n_samples x 1\n",
    "        subject_data: DataFrame of subject labels. Shape: n_samples x 1\n",
    "        window_size: Size of the window for arranging data.   \n",
    "        stride: Stride for the sliding window.  \n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 image_data, \n",
    "                 e_labels_data,\n",
    "                 transform=None):\n",
    "\n",
    "        self.image_data = image_data\n",
    "        self.e_labels_data = e_labels_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        e_labels = self.e_labels_data[idx]\n",
    "\n",
    "        return (image, \n",
    "                e_labels)\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "\n",
    "    def __init__(self, size, padding=0):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.padding = padding\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, img):\n",
    "\n",
    "        if self.padding > 0:\n",
    "            img = ImageOps.expand(img, border=self.padding, fill=0)\n",
    "\n",
    "        w, h = img.size\n",
    "        th, tw = self.size\n",
    "        if w == tw and h == th:\n",
    "            return img\n",
    "\n",
    "        random.seed(self.count // 10)\n",
    "        x1 = random.randint(0, w - tw)\n",
    "        y1 = random.randint(0, h - th)\n",
    "        # print(self.count, x1, y1)\n",
    "        self.count += 1\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "    \n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, img):\n",
    "        seed = self.count // 10\n",
    "        random.seed(seed)\n",
    "        prob = random.random()\n",
    "        self.count += 1\n",
    "        # print(self.count, seed, prob)\n",
    "        if prob < 0.5:\n",
    "            return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return img\n",
    "    \n",
    "\n",
    "class RandomRotation(object):\n",
    "    def __init__(self, degrees):\n",
    "        self.degrees = degrees\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, img):\n",
    "        seed = self.count // 10\n",
    "        random.seed(seed)\n",
    "        self.count += 1\n",
    "        angle = random.randint(-self.degrees, self.degrees)\n",
    "        return TF.rotate(img, angle)\n",
    "\n",
    "\n",
    "class ColorJitter(object):\n",
    "    def __init__(self, brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1):\n",
    "        self.brightness = brightness\n",
    "        self.contrast = contrast\n",
    "        self.saturation = saturation\n",
    "        self.hue = hue\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, img):\n",
    "        seed = self.count // 10\n",
    "        random.seed(seed)\n",
    "        self.count += 1\n",
    "        brightness_factor = random.uniform(1 - self.brightness, 1 + self.brightness)\n",
    "        contrast_factor = random.uniform(1 - self.contrast, 1 + self.contrast)\n",
    "        saturation_factor = random.uniform(1 - self.saturation, 1 + self.saturation)\n",
    "        hue_factor = random.uniform(- self.hue, self.hue)\n",
    "\n",
    "        img_ = TF.adjust_brightness(img, brightness_factor)\n",
    "        img_ = TF.adjust_contrast(img_, contrast_factor)\n",
    "        img_ = TF.adjust_saturation(img_, saturation_factor)\n",
    "        img_ = TF.adjust_hue(img_, hue_factor)\n",
    "\n",
    "        return img_\n",
    "\n",
    "class NumpyToPIL(object):\n",
    "    def __call__(self, array):\n",
    "        return Image.fromarray(array.astype('uint8'))\n",
    "    \n",
    "\n",
    "\n",
    "def image_train_transform(mean, std):\n",
    "    train_transforms = transforms.Compose([\n",
    "            NumpyToPIL(),\n",
    "            ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "            RandomHorizontalFlip(),\n",
    "            RandomRotation(5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    \n",
    "    return train_transforms\n",
    "\n",
    "\n",
    "def image_transform(mean, std):\n",
    "    \n",
    "    #Inputs: mean and std of the images\n",
    "    #Outputs: transformation object:\n",
    "        # Normalize and Standardize\n",
    "    transform =  transforms.Compose([\n",
    "        lambda x: x/255.0,\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LOSO Cross-Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11fd94e90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = False\n",
    "if cuda:\n",
    "    torch.cuda.empty_cache() # Clear cache\n",
    "    \n",
    "else:\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "outs = ['1Out', '2Out', '3Out', '4Out', '5Out']\n",
    "exp_kwargs = {\"batch_size\": 32,\n",
    "              \"epochs\": 5,\n",
    "              \"lr\": 5e-4,\n",
    "              \"weight_decay\": 1e-3}\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.manual_seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 2Out...\n",
      "Loaded 27792 training samples.\n",
      "Loaded 6056 testing samples.\n",
      "Creating datasets and dataloaders...\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 869/869 [08:52<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6258, Train Accuracy: 65.22%\n",
      "Test Loss: 0.6607, Test Accuracy: 58.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [08:47<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.5966, Train Accuracy: 68.45%\n",
      "Test Loss: 0.7805, Test Accuracy: 54.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [08:43<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.5656, Train Accuracy: 71.54%\n",
      "Test Loss: 0.7561, Test Accuracy: 55.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/869 [00:09<08:39,  1.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(exp_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 51\u001b[0m     train_loss, correct_train, total_train \u001b[38;5;241m=\u001b[39m train_single_epoch(model, train_dataloader, device, criterion, optimizer)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mcorrect_train\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mtotal_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36mtrain_single_epoch\u001b[0;34m(model, train_dataloader, device, criterion, optimizer)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#Backward pass\u001b[39;00m\n\u001b[1;32m     79\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 80\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     81\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#Metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.mps.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "for out in outs:\n",
    "\n",
    "    #a. Load training and testing data\n",
    "    print(f\"Loading data for LOSO with trial {out}...\")\n",
    "    root_data_path = '../data/LOSO/5Hz_All/'\n",
    "    fold_data_path = '../data/LOSO/5Hz/' + out + '/'\n",
    "    \n",
    "    images_train, e_labels_train = load_data(root_data_path=root_data_path, fold_data_path=fold_data_path, csv_filename='train.csv')\n",
    "    print(f\"Loaded {len(images_train)} training samples.\")\n",
    "    images_test, e_labels_test = load_data(root_data_path=root_data_path, fold_data_path=fold_data_path, csv_filename='test.csv')\n",
    "    print(f\"Loaded {len(images_test)} testing samples.\")\n",
    "\n",
    "    e_labels_train = e_labels_train[:, -1]\n",
    "    e_labels_test =  e_labels_test[:, -1]\n",
    "\n",
    "    mean_fold = torch.load(os.path.join(fold_data_path, \"mean.pth\"))\n",
    "    std_fold = torch.load(os.path.join(fold_data_path, \"std.pth\"))\n",
    "    transform_train = image_transform(mean=mean_fold, std=std_fold)\n",
    "    transform_test = image_transform(mean=mean_fold, std= std_fold)\n",
    "\n",
    "    #b. Create dataset and dataloader\n",
    "    print(\"Creating datasets and dataloaders...\")\n",
    "    train_dataset = CustomVideoDataset(image_data=images_train, e_labels_data=e_labels_train, transform=transform_train)\n",
    "    test_dataset = CustomVideoDataset(image_data=images_test, e_labels_data=e_labels_test, transform=transform_test)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=exp_kwargs[\"batch_size\"], shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=exp_kwargs[\"batch_size\"], shuffle=False, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    #c. Model, loss and optimizer\n",
    "    print(\"Creating model...\")\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 1)  # Output layer for binary classification\n",
    "    )\n",
    "    model = model.to(device)  \n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=exp_kwargs[\"lr\"],\n",
    "        eps=1e-8, weight_decay=exp_kwargs[\"weight_decay\"]\n",
    "        )\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_losses, test_losses, train_acc, test_acc = [], [], [], []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(exp_kwargs['epochs']):\n",
    "        \n",
    "        train_loss, correct_train, total_train = train_single_epoch(model, train_dataloader, device, criterion, optimizer)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_dataloader):.4f}, Train Accuracy: {100 * correct_train / total_train:.2f}%\")\n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        acc = correct_train / total_train\n",
    "        train_acc.append(acc)\n",
    "                          \n",
    "        #Test set evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_dataloader):\n",
    "                images, labels = images.type(torch.float32).to(device), labels.type(torch.float32).to(device)\n",
    "\n",
    "                if i == 0:\n",
    "                    test_loss, correct_test, total_test = 0, 0, 0\n",
    "\n",
    "                outputs = model(images).view(-1, 1)\n",
    "                labels = labels.view(-1, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                preds = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "                correct_test += (preds == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "\n",
    "        print(f\"Test Loss: {test_loss/len(test_dataloader):.4f}, Test Accuracy: {100 * correct_test / total_test:.2f}%\")\n",
    "        test_losses.append(test_loss/len(test_dataloader))\n",
    "        acc_test = correct_test / total_test\n",
    "        test_acc.append(acc_test)\n",
    "\n",
    "        if acc_test > best_acc:\n",
    "            best_acc = acc_test\n",
    "            torch.save(model.state_dict(), f\"../models/ResNet50_5Hz/{out}_epoch_{epoch}.pth\")\n",
    "\n",
    "    plot_losses(train_losses, test_losses, test=True, out=out)\n",
    "    plot_accs(train_acc, test_acc, test=True, out = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Performance Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 1Out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 3/798 [00:02<10:22,  1.28it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:59: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:60: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:61: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "  2%|▏         | 5/261 [00:00<00:45,  5.66it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:82: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:83: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:84: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 2Out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 3/869 [00:04<19:58,  1.38s/it]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:59: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:60: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:61: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "  3%|▎         | 5/190 [00:00<00:34,  5.42it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:82: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:83: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:84: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 3Out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 3/837 [00:03<14:12,  1.02s/it]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:59: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:60: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:61: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "  2%|▏         | 5/221 [00:00<00:38,  5.67it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:82: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:83: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:84: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 4Out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 3/842 [00:03<18:22,  1.31s/it]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:59: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:60: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:61: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "  2%|▏         | 5/217 [00:00<00:37,  5.68it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:82: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:83: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:84: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for LOSO with trial 5Out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 3/887 [00:03<19:11,  1.30s/it]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:59: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:60: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:61: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
      "  3%|▎         | 5/171 [00:00<00:30,  5.46it/s]\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:82: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:83: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_7284/3094390386.py:84: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "true_train, pred_train, samples_train, true_test, pred_test, samples_test = [], [], [], [], [], []  \n",
    "acc_train, f1_train, jaccard_train, acc_test, f1_test, jaccard_test = [], [], [], [], [], []\n",
    "\n",
    "for out in outs:\n",
    "\n",
    "    print(f\"Loading data for LOSO with trial {out}...\")\n",
    "    root_data_path = '../data/LOSO/5Hz_All/'\n",
    "    fold_data_path = '../data/LOSO/15Hz/' + out + '/'\n",
    "    \n",
    "    images_train, e_labels_train = load_data(root_data_path=root_data_path, fold_data_path=fold_data_path, csv_filename='train.csv')\n",
    "    images_test, e_labels_test = load_data(root_data_path=root_data_path, fold_data_path=fold_data_path, csv_filename='test.csv')\n",
    "\n",
    "    e_labels_train = e_labels_train[:, -1]\n",
    "    e_labels_test =  e_labels_test[:, -1]\n",
    "\n",
    "    mean_fold = torch.load(os.path.join(fold_data_path, \"mean.pth\"))\n",
    "    std_fold = torch.load(os.path.join(fold_data_path, \"std.pth\"))\n",
    "    transform = image_transform(mean=mean_fold, std= std_fold)\n",
    "\n",
    "    #b. Create dataset and dataloader\n",
    "    train_dataset = CustomVideoDataset(image_data=images_train, e_labels_data=e_labels_train, transform=transform)\n",
    "    test_dataset = CustomVideoDataset(image_data=images_test, e_labels_data=e_labels_test, transform=transform)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=exp_kwargs[\"batch_size\"], shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=exp_kwargs[\"batch_size\"], shuffle=False, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Linear(2048, 1)\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"../models/ResNet50/{out}.pth\"))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "\n",
    "    true_train_fold, pred_train_fold = [], []\n",
    "    true_test_fold, pred_test_fold = [], []\n",
    "    samples_train_fold, samples_test_fold = len(train_dataset), len(test_dataset)\n",
    "    samples_train.append(samples_train_fold)\n",
    "    samples_test.append(samples_test_fold)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, (images, labels) in tqdm.tqdm(enumerate(train_dataloader),\n",
    "                                        total = len(train_dataloader)):\n",
    "                \n",
    "            images, labels = images.type(torch.float32).to(device), labels.type(torch.float32).to(device)\n",
    "            #Forward pass\n",
    "            outputs = model(images).view(-1, 1)\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "            true_train_fold.append(labels.detach().cpu())\n",
    "            pred_train_fold.append(preds.detach().cpu())\n",
    "\n",
    "            if i == 3:\n",
    "                break\n",
    "        \n",
    "        true_train_fold = torch.cat(true_train_fold, dim = 0).squeeze()\n",
    "        pred_train_fold = torch.cat(pred_train_fold, dim=0).squeeze()\n",
    "        acc_train.append(accuracy_score(np.array(true_train_fold), np.array(pred_train_fold)))\n",
    "        f1_train.append(f1_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
    "        jaccard_train.append(jaccard_score(np.array(true_train_fold), np.array(pred_train_fold), average='binary', pos_label=1))\n",
    "\n",
    "        \n",
    "        for i, (images, labels) in tqdm.tqdm(enumerate(test_dataloader),\n",
    "                                                total = len(test_dataloader)):\n",
    "                \n",
    "            images, labels = images.type(torch.float32).to(device), labels.type(torch.float32).to(device)   \n",
    "\n",
    "            #Forward pass\n",
    "            outputs = model(images).view(-1, 1)\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "            true_test_fold.append(labels.detach().cpu())\n",
    "            pred_test_fold.append(preds.detach().cpu())\n",
    "\n",
    "            if i ==5:\n",
    "                break\n",
    "\n",
    "        true_test_fold = torch.cat(true_test_fold, dim = 0).squeeze()\n",
    "        pred_test_fold = torch.cat(pred_test_fold, dim=0).squeeze()\n",
    "        acc_test.append(accuracy_score(np.array(true_test_fold), np.array(pred_test_fold)))\n",
    "        f1_test.append(f1_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))\n",
    "        jaccard_test.append(jaccard_score(np.array(true_test_fold), np.array(pred_test_fold), average='binary', pos_label=1))    \n",
    "\n",
    "    true_train.append(true_train_fold)\n",
    "    pred_train.append(pred_train_fold)    \n",
    "    true_test.append(true_test_fold)\n",
    "    pred_test.append(pred_test_fold)   \n",
    "\n",
    "    del train_dataloader, test_dataloader, model\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Jaccard Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.56 +- 0.05</td>\n",
       "      <td>0.69 +- 0.05</td>\n",
       "      <td>0.52 +- 0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy      F1 Score Jaccard Index\n",
       "Train  0.56 +- 0.05  0.69 +- 0.05  0.52 +- 0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Jaccard Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.42 +- 0.15</td>\n",
       "      <td>0.42 +- 0.27</td>\n",
       "      <td>0.30 +- 0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy      F1 Score Jaccard Index\n",
       "Test  0.42 +- 0.15  0.42 +- 0.27  0.30 +- 0.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m train_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/ResNet50/train_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m test_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/ResNet50/test_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m true_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(true_train, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze() \n\u001b[1;32m     23\u001b[0m pred_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(pred_train, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     24\u001b[0m true_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(true_test, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test dataframes with results: avg +- std for acc, f1, and jaccard\n",
    "train_results = pd.DataFrame({\n",
    "    'Accuracy': f\"{np.mean(acc_train):.2f} +- {np.std(acc_train):.2f}\",\n",
    "    'F1 Score': f\"{np.mean(f1_train):.2f} +- {np.std(f1_train):.2f}\",\n",
    "    'Jaccard Index': f\"{np.mean(jaccard_train):.2f} +- {np.std(jaccard_train):.2f}\"\n",
    "},index = ['Train'])\n",
    "\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'Accuracy': f\"{np.mean(acc_test):.2f} +- {np.std(acc_test):.2f}\",\n",
    "    'F1 Score': f\"{np.mean(f1_test):.2f} +- {np.std(f1_test):.2f}\",\n",
    "    'Jaccard Index': f\"{np.mean(jaccard_test):.2f} +- {np.std(jaccard_test):.2f}\"\n",
    "}, index = ['Test'])\n",
    "\n",
    "display(train_results)\n",
    "display(test_results)\n",
    "\n",
    "#Save as csv files in ../results/ResNet50/\n",
    "train_results.to_csv('../results/ResNet50/train_results.csv')\n",
    "test_results.to_csv('../results/ResNet50/test_results.csv')\n",
    "\n",
    "true_train = torch.cat(true_train, dim=0).squeeze() \n",
    "pred_train = torch.cat(pred_train, dim=0).squeeze()\n",
    "true_test = torch.cat(true_test, dim=0).squeeze()\n",
    "pred_test = torch.cat(pred_test, dim=0).squeeze()\n",
    "\n",
    "#display_sklearn_reports(np.array(true_train), np.array(pred_train), train_or_val=\"Train\", ax = ax[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/qy9bk4_94zsb04lj0tpx7vx40000gn/T/ipykernel_5741/980863415.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  display_sklearn_reports(np.array(true_test), np.array(pred_test), train_or_val=\"Test\", ax = ax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Test set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "0 (No error)       0.30      0.02      0.05     15540\n",
      "   1 (Error)       0.53      0.95      0.68     18308\n",
      "\n",
      "    accuracy                           0.53     33848\n",
      "   macro avg       0.42      0.49      0.36     33848\n",
      "weighted avg       0.43      0.53      0.39     33848\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1787.5x625 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14.3, 5))\n",
    "display_sklearn_reports(np.array(true_test), np.array(pred_test), train_or_val=\"Test\", ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
